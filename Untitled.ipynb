{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import tqdm\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image as im\n",
    "from keras import layers as L\n",
    "from keras import backend as K\n",
    "from keras import activations as A\n",
    "from keras import losses\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_reso = (1050, 700)\n",
    "input_shape = (700, 1050, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"datasets/train.csv\")\n",
    "test_csv = pd.read_csv(\"datasets/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.memmap(\"datasets/train.npy\", dtype=np.uint8, mode=\"w+\", shape=(train_csv.shape[0], 700, 1050, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea86ec3b1cb0411b8c21da2e2fdd8aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25361), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm_notebook(range(train_csv.shape[0])):\n",
    "    image = train_csv.iloc[i, 0]\n",
    "    img = im.open(\"datasets/train/%s\"%image)\n",
    "    if img.size != most_common_reso:\n",
    "        img = img.resize(most_common_reso)\n",
    "    array = np.asarray(img)\n",
    "    img.close()\n",
    "    if len(array.shape) == 2:\n",
    "        array = np.expand_dims(array, 2)\n",
    "        array = np.concatenate([array]*3, axis=-1)\n",
    "    dataset[i] = array\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = {id_:list() for id_ in train_csv.Id.unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(train_csv.shape[0]):\n",
    "    indices[train_csv.iloc[i,1]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(indices)\n",
    "ids_no_new = ids[:]\n",
    "ids_no_new.remove(\"new_whale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(batch_size=32):\n",
    "    batch_features_1, batch_features_2 = np.zeros((2*batch_size, 700, 1050, 3)), np.zeros((2*batch_size, 700, 1050, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((2*batch_size, 1))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            while True:\n",
    "                id_ = random.choice(ids_no_new)\n",
    "                if len(indices[id_])>=2:\n",
    "                    break\n",
    "            idx_1, idx_2 = random.sample(indices[id_], 2)\n",
    "            batch_features_1[i] = dataset[idx_1]/255.\n",
    "            batch_features_2[i] = dataset[idx_2]/255.\n",
    "            batch_labels[i, 0] = 0\n",
    "        for i in range(batch_size, 2*batch_size):\n",
    "            id_1, id_2 = random.sample(ids, 2)\n",
    "            idx_1, idx_2 = random.choice(indices[id_1]), random.choice(indices[id_2])\n",
    "            batch_features_1[i] = dataset[idx_1]/255.\n",
    "            batch_features_2[i] = dataset[idx_2]/255.\n",
    "            batch_labels[i, 0] = 1\n",
    "        \n",
    "        yield [batch_features_1, batch_features_2], batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    input_ = L.Input(shape=input_shape)\n",
    "    x = L.Conv2D(filters=8, kernel_size=3, strides=1, padding=\"same\", activation=None)(input_)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=8, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x = L.Conv2D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x = L.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x = L.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=32, kernel_size=1, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x = L.Conv2D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=16, kernel_size=3, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.Conv2D(filters=16, kernel_size=1, strides=1, padding=\"same\", activation=None)(x)\n",
    "    x = L.Activation(activation=A.relu)(x)\n",
    "    x = L.MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    \n",
    "    x = L.Flatten()(x)\n",
    "    x = L.Dense(2048, activation=A.relu)(x)\n",
    "    x = L.Dense(1024, activation=A.relu)(x)\n",
    "    x = L.Dense(512, activation=A.relu)(x)\n",
    "    x = L.Dense(256, activation=A.relu)(x)\n",
    "    x = L.Dense(128, activation=A.relu)(x)\n",
    "    #x = L.Dense(64, activation=A.relu)(x)\n",
    "    return Model(input_, x)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = L.Input(shape=input_shape)\n",
    "input_b = L.Input(shape=input_shape)\n",
    "base_network = create_base_network(input_shape)\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = L.Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(1e-3)\n",
    "model.compile(loss=contrastive_loss, optimizer=opt, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2803 - accuracy: 0.5210\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2729 - accuracy: 0.5366\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2697 - accuracy: 0.5400\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 173s 5s/step - loss: 0.2694 - accuracy: 0.5293\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2698 - accuracy: 0.5435\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2556 - accuracy: 0.5752\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2715 - accuracy: 0.5386\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2679 - accuracy: 0.5391\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2713 - accuracy: 0.5327\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2596 - accuracy: 0.5713\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2569 - accuracy: 0.5566\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 169s 5s/step - loss: 0.2564 - accuracy: 0.5771\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2624 - accuracy: 0.5586\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2584 - accuracy: 0.5645\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2608 - accuracy: 0.5664\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2656 - accuracy: 0.5586\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2667 - accuracy: 0.5488\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 144s 4s/step - loss: 0.2610 - accuracy: 0.5542\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2598 - accuracy: 0.5630\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2574 - accuracy: 0.5698\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2612 - accuracy: 0.5713\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2602 - accuracy: 0.5654\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2565 - accuracy: 0.5854\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2525 - accuracy: 0.5815\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2605 - accuracy: 0.5630\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 146s 5s/step - loss: 0.2546 - accuracy: 0.5854\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 165s 5s/step - loss: 0.2541 - accuracy: 0.5806\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2568 - accuracy: 0.5684\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2501 - accuracy: 0.5850\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2585 - accuracy: 0.5728\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2553 - accuracy: 0.5825\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2579 - accuracy: 0.5786\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2502 - accuracy: 0.5986\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 171s 5s/step - loss: 0.2650 - accuracy: 0.5620\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2437 - accuracy: 0.5977\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 165s 5s/step - loss: 0.2530 - accuracy: 0.5811\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2554 - accuracy: 0.5737\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2516 - accuracy: 0.5874\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2492 - accuracy: 0.5977\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 143s 4s/step - loss: 0.2547 - accuracy: 0.5776\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2560 - accuracy: 0.5767\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 142s 4s/step - loss: 0.2503 - accuracy: 0.5884\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2444 - accuracy: 0.6040\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2456 - accuracy: 0.6050\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2444 - accuracy: 0.5957\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2480 - accuracy: 0.5928\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2380 - accuracy: 0.6113\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2604 - accuracy: 0.5684\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2538 - accuracy: 0.5918\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2549 - accuracy: 0.5703\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2509 - accuracy: 0.5977\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2431 - accuracy: 0.6143\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2516 - accuracy: 0.5903\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2429 - accuracy: 0.6055\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2437 - accuracy: 0.6030\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2514 - accuracy: 0.5840\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2512 - accuracy: 0.5869\n",
      "Epoch 59/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2421 - accuracy: 0.6064\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2432 - accuracy: 0.6079\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2428 - accuracy: 0.6055\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2410 - accuracy: 0.6138\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2340 - accuracy: 0.6226\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2436 - accuracy: 0.6035\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2365 - accuracy: 0.6133\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2414 - accuracy: 0.6089\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2486 - accuracy: 0.5923\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2451 - accuracy: 0.6030\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2468 - accuracy: 0.5908\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2418 - accuracy: 0.5967\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2389 - accuracy: 0.6084\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2451 - accuracy: 0.6147\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2371 - accuracy: 0.6162\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2384 - accuracy: 0.6138\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2358 - accuracy: 0.6162\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2467 - accuracy: 0.5991\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2441 - accuracy: 0.6118\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2388 - accuracy: 0.6255\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2424 - accuracy: 0.6084\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2365 - accuracy: 0.6240\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2369 - accuracy: 0.6221\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 161s 5s/step - loss: 0.2375 - accuracy: 0.6172\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2347 - accuracy: 0.6230\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2440 - accuracy: 0.6040\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2350 - accuracy: 0.6138\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2318 - accuracy: 0.6226\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2402 - accuracy: 0.6069\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2308 - accuracy: 0.6431\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2383 - accuracy: 0.6182\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2385 - accuracy: 0.6099\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2403 - accuracy: 0.6074\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2285 - accuracy: 0.6353\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2330 - accuracy: 0.6196\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 166s 5s/step - loss: 0.2498 - accuracy: 0.5991\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2402 - accuracy: 0.6162\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2398 - accuracy: 0.6113\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2367 - accuracy: 0.6177\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 163s 5s/step - loss: 0.2387 - accuracy: 0.6118\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2329 - accuracy: 0.6377\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2314 - accuracy: 0.6338\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2333 - accuracy: 0.6274\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2360 - accuracy: 0.6226\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2363 - accuracy: 0.6138\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2321 - accuracy: 0.6147\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2368 - accuracy: 0.6094\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2334 - accuracy: 0.6289\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2336 - accuracy: 0.6138\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2374 - accuracy: 0.6094\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2330 - accuracy: 0.6240\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 144s 5s/step - loss: 0.2278 - accuracy: 0.6304\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2287 - accuracy: 0.6338\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2392 - accuracy: 0.6074\n",
      "Epoch 113/1000\n",
      "15/32 [=============>................] - ETA: 1:14 - loss: 0.2296 - accuracy: 0.6292"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 168s 5s/step - loss: 0.2184 - accuracy: 0.6641\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2155 - accuracy: 0.6636\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2207 - accuracy: 0.6528\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2138 - accuracy: 0.6616\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2184 - accuracy: 0.6553\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2129 - accuracy: 0.6812\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2220 - accuracy: 0.6533\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2180 - accuracy: 0.6611\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2170 - accuracy: 0.6704\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2143 - accuracy: 0.6729\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2118 - accuracy: 0.6812\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2106 - accuracy: 0.6880\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2096 - accuracy: 0.6909\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2171 - accuracy: 0.6689\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2165 - accuracy: 0.6753\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2181 - accuracy: 0.6606\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2201 - accuracy: 0.6499\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2155 - accuracy: 0.6733\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2137 - accuracy: 0.6641\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2159 - accuracy: 0.6660\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2145 - accuracy: 0.6665\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2171 - accuracy: 0.6655\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2079 - accuracy: 0.6797\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2181 - accuracy: 0.6680\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2195 - accuracy: 0.6489\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2188 - accuracy: 0.6489\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2204 - accuracy: 0.6460\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2230 - accuracy: 0.6377\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2237 - accuracy: 0.6450\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2192 - accuracy: 0.6611\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2161 - accuracy: 0.6592\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2166 - accuracy: 0.6504\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 166s 5s/step - loss: 0.2143 - accuracy: 0.6719\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2096 - accuracy: 0.6680\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2167 - accuracy: 0.6592\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2208 - accuracy: 0.6528\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2138 - accuracy: 0.6807\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2194 - accuracy: 0.6646\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2151 - accuracy: 0.6660\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2164 - accuracy: 0.6636\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 163s 5s/step - loss: 0.2137 - accuracy: 0.6841\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2212 - accuracy: 0.6636\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2178 - accuracy: 0.6606\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2175 - accuracy: 0.6514\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2172 - accuracy: 0.6650\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2227 - accuracy: 0.6572\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 300s 9s/step - loss: 0.2142 - accuracy: 0.6758\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 167s 5s/step - loss: 0.2131 - accuracy: 0.6567\n",
      "Epoch 291/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2142 - accuracy: 0.6533\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2162 - accuracy: 0.6626\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2128 - accuracy: 0.6685\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2201 - accuracy: 0.6577\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2083 - accuracy: 0.6831\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 165s 5s/step - loss: 0.2164 - accuracy: 0.6606\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2154 - accuracy: 0.6621\n",
      "Epoch 298/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2175 - accuracy: 0.6782\n",
      "Epoch 299/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2197 - accuracy: 0.6587\n",
      "Epoch 300/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2087 - accuracy: 0.6821\n",
      "Epoch 301/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2179 - accuracy: 0.6528\n",
      "Epoch 302/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2129 - accuracy: 0.6636\n",
      "Epoch 303/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2171 - accuracy: 0.6807\n",
      "Epoch 304/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2157 - accuracy: 0.6758\n",
      "Epoch 305/1000\n",
      "32/32 [==============================] - 171s 5s/step - loss: 0.2174 - accuracy: 0.6641\n",
      "Epoch 306/1000\n",
      "32/32 [==============================] - 140s 4s/step - loss: 0.2118 - accuracy: 0.6836\n",
      "Epoch 307/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2133 - accuracy: 0.6772\n",
      "Epoch 308/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2091 - accuracy: 0.6909\n",
      "Epoch 309/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2158 - accuracy: 0.6655\n",
      "Epoch 310/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2157 - accuracy: 0.6631\n",
      "Epoch 311/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2102 - accuracy: 0.6797\n",
      "Epoch 312/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2088 - accuracy: 0.6831\n",
      "Epoch 313/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2041 - accuracy: 0.6938\n",
      "Epoch 314/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2133 - accuracy: 0.6699\n",
      "Epoch 315/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2217 - accuracy: 0.6558\n",
      "Epoch 316/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2103 - accuracy: 0.6831\n",
      "Epoch 317/1000\n",
      "32/32 [==============================] - 164s 5s/step - loss: 0.2126 - accuracy: 0.6704\n",
      "Epoch 318/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2124 - accuracy: 0.6724\n",
      "Epoch 319/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2178 - accuracy: 0.6582\n",
      "Epoch 320/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2182 - accuracy: 0.6602\n",
      "Epoch 321/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2199 - accuracy: 0.6538\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 155s 5s/step - loss: 0.2116 - accuracy: 0.6758\n",
      "Epoch 323/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2103 - accuracy: 0.6680\n",
      "Epoch 324/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2068 - accuracy: 0.6870\n",
      "Epoch 325/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2063 - accuracy: 0.6836\n",
      "Epoch 326/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2093 - accuracy: 0.6875\n",
      "Epoch 327/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2119 - accuracy: 0.6865\n",
      "Epoch 328/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2222 - accuracy: 0.6543\n",
      "Epoch 329/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2073 - accuracy: 0.6826\n",
      "Epoch 330/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2082 - accuracy: 0.6890\n",
      "Epoch 331/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2080 - accuracy: 0.6851\n",
      "Epoch 332/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2087 - accuracy: 0.6797\n",
      "Epoch 333/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2181 - accuracy: 0.6670\n",
      "Epoch 334/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2160 - accuracy: 0.6719\n",
      "Epoch 335/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2148 - accuracy: 0.6685\n",
      "Epoch 336/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2146 - accuracy: 0.6636\n",
      "Epoch 337/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2096 - accuracy: 0.6836\n",
      "Epoch 338/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2104 - accuracy: 0.6641\n",
      "Epoch 339/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2134 - accuracy: 0.6611\n",
      "Epoch 340/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2100 - accuracy: 0.6772\n",
      "Epoch 341/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2105 - accuracy: 0.6787\n",
      "Epoch 342/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2084 - accuracy: 0.6758\n",
      "Epoch 343/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2045 - accuracy: 0.6885\n",
      "Epoch 344/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2073 - accuracy: 0.6860\n",
      "Epoch 345/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2061 - accuracy: 0.6851\n",
      "Epoch 346/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2129 - accuracy: 0.6772\n",
      "Epoch 347/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2081 - accuracy: 0.6831\n",
      "Epoch 348/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2119 - accuracy: 0.6758\n",
      "Epoch 349/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2089 - accuracy: 0.6821\n",
      "Epoch 350/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2146 - accuracy: 0.6675\n",
      "Epoch 351/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2077 - accuracy: 0.6777\n",
      "Epoch 352/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2131 - accuracy: 0.6719\n",
      "Epoch 353/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2076 - accuracy: 0.6885\n",
      "Epoch 354/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2135 - accuracy: 0.6787\n",
      "Epoch 355/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2097 - accuracy: 0.6846\n",
      "Epoch 356/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2104 - accuracy: 0.6772\n",
      "Epoch 357/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2071 - accuracy: 0.6890\n",
      "Epoch 358/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2147 - accuracy: 0.6631\n",
      "Epoch 359/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2118 - accuracy: 0.6768\n",
      "Epoch 360/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2095 - accuracy: 0.6914\n",
      "Epoch 361/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2069 - accuracy: 0.6851\n",
      "Epoch 362/1000\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2146 - accuracy: 0.6709\n",
      "Epoch 363/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2113 - accuracy: 0.6729\n",
      "Epoch 364/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2135 - accuracy: 0.6719\n",
      "Epoch 365/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2076 - accuracy: 0.6787\n",
      "Epoch 366/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2119 - accuracy: 0.6802\n",
      "Epoch 367/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2095 - accuracy: 0.6675\n",
      "Epoch 368/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2197 - accuracy: 0.6475\n",
      "Epoch 369/1000\n",
      "32/32 [==============================] - 191s 6s/step - loss: 0.2133 - accuracy: 0.6724\n",
      "Epoch 370/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2120 - accuracy: 0.6855\n",
      "Epoch 371/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2056 - accuracy: 0.6909\n",
      "Epoch 372/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2100 - accuracy: 0.6807\n",
      "Epoch 373/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2065 - accuracy: 0.6880\n",
      "Epoch 374/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2177 - accuracy: 0.6665\n",
      "Epoch 375/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2129 - accuracy: 0.6792\n",
      "Epoch 376/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2216 - accuracy: 0.6509\n",
      "Epoch 377/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2129 - accuracy: 0.6792\n",
      "Epoch 378/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2171 - accuracy: 0.6592\n",
      "Epoch 379/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2108 - accuracy: 0.6807\n",
      "Epoch 380/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2083 - accuracy: 0.6943\n",
      "Epoch 381/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2105 - accuracy: 0.6855\n",
      "Epoch 382/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2078 - accuracy: 0.6826\n",
      "Epoch 383/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2082 - accuracy: 0.6890\n",
      "Epoch 384/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2156 - accuracy: 0.6626\n",
      "Epoch 385/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2121 - accuracy: 0.6758\n",
      "Epoch 386/1000\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.2109 - accuracy: 0.6748\n",
      "Epoch 387/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2087 - accuracy: 0.6738\n",
      "Epoch 388/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2164 - accuracy: 0.6606\n",
      "Epoch 389/1000\n",
      "32/32 [==============================] - 148s 5s/step - loss: 0.2093 - accuracy: 0.6851\n",
      "Epoch 390/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2125 - accuracy: 0.6704\n",
      "Epoch 391/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2119 - accuracy: 0.6729\n",
      "Epoch 392/1000\n",
      "32/32 [==============================] - 169s 5s/step - loss: 0.2056 - accuracy: 0.6826\n",
      "Epoch 393/1000\n",
      "32/32 [==============================] - 165s 5s/step - loss: 0.2045 - accuracy: 0.6792\n",
      "Epoch 394/1000\n",
      "32/32 [==============================] - 164s 5s/step - loss: 0.2082 - accuracy: 0.6768\n",
      "Epoch 395/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.2076 - accuracy: 0.6943\n",
      "Epoch 396/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2145 - accuracy: 0.6680\n",
      "Epoch 397/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2101 - accuracy: 0.6890\n",
      "Epoch 398/1000\n",
      "32/32 [==============================] - 164s 5s/step - loss: 0.2121 - accuracy: 0.6772\n",
      "Epoch 399/1000\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.2078 - accuracy: 0.6787\n",
      "Epoch 400/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2085 - accuracy: 0.6768\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 157s 5s/step - loss: 0.2168 - accuracy: 0.6689\n",
      "Epoch 402/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2103 - accuracy: 0.6851\n",
      "Epoch 403/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2089 - accuracy: 0.6807\n",
      "Epoch 404/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2112 - accuracy: 0.6704\n",
      "Epoch 405/1000\n",
      "32/32 [==============================] - 167s 5s/step - loss: 0.2052 - accuracy: 0.6899\n",
      "Epoch 406/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2042 - accuracy: 0.6909\n",
      "Epoch 407/1000\n",
      "32/32 [==============================] - 150s 5s/step - loss: 0.2160 - accuracy: 0.6670\n",
      "Epoch 408/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2097 - accuracy: 0.6821\n",
      "Epoch 409/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2065 - accuracy: 0.6870\n",
      "Epoch 410/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2032 - accuracy: 0.6885\n",
      "Epoch 411/1000\n",
      "32/32 [==============================] - 163s 5s/step - loss: 0.2110 - accuracy: 0.6768\n",
      "Epoch 412/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2032 - accuracy: 0.7026\n",
      "Epoch 413/1000\n",
      "32/32 [==============================] - 166s 5s/step - loss: 0.2043 - accuracy: 0.6934\n",
      "Epoch 414/1000\n",
      "32/32 [==============================] - 156s 5s/step - loss: 0.2024 - accuracy: 0.6919\n",
      "Epoch 415/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2070 - accuracy: 0.6865\n",
      "Epoch 416/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2082 - accuracy: 0.6919\n",
      "Epoch 417/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2122 - accuracy: 0.6689\n",
      "Epoch 418/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2094 - accuracy: 0.6772\n",
      "Epoch 419/1000\n",
      "32/32 [==============================] - 158s 5s/step - loss: 0.2121 - accuracy: 0.6719\n",
      "Epoch 420/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2122 - accuracy: 0.6689\n",
      "Epoch 421/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2130 - accuracy: 0.6689\n",
      "Epoch 422/1000\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.2021 - accuracy: 0.7012\n",
      "Epoch 423/1000\n",
      "32/32 [==============================] - 162s 5s/step - loss: 0.2112 - accuracy: 0.6895\n",
      "Epoch 424/1000\n",
      "32/32 [==============================] - 165s 5s/step - loss: 0.2073 - accuracy: 0.6870\n",
      "Epoch 425/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2109 - accuracy: 0.6777\n",
      "Epoch 426/1000\n",
      "32/32 [==============================] - 157s 5s/step - loss: 0.2122 - accuracy: 0.6763\n",
      "Epoch 427/1000\n",
      "32/32 [==============================] - 160s 5s/step - loss: 0.2134 - accuracy: 0.6675\n",
      "Epoch 428/1000\n",
      "32/32 [==============================] - 153s 5s/step - loss: 0.2134 - accuracy: 0.6743\n",
      "Epoch 429/1000\n",
      "32/32 [==============================] - 159s 5s/step - loss: 0.2061 - accuracy: 0.6875\n",
      "Epoch 430/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2092 - accuracy: 0.6787\n",
      "Epoch 431/1000\n",
      "32/32 [==============================] - 161s 5s/step - loss: 0.2143 - accuracy: 0.6626\n",
      "Epoch 432/1000\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.2118 - accuracy: 0.6689\n",
      "Epoch 433/1000\n",
      "32/32 [==============================] - 152s 5s/step - loss: 0.2123 - accuracy: 0.6860\n",
      "Epoch 434/1000\n",
      "32/32 [==============================] - 151s 5s/step - loss: 0.1981 - accuracy: 0.7100\n",
      "Epoch 435/1000\n",
      "18/32 [===============>..............] - ETA: 1:09 - loss: 0.2047 - accuracy: 0.6736"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-0eb59832ff44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=generator(batch_size=32), steps_per_epoch=32, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_v, tr_l = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tr_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27734375"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
